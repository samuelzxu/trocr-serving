2023-03-19T14:10:39,491 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-03-19T14:10:39,495 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Successfully loaded /home/ziggy/miniconda3/envs/ts-testing/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2023-03-19T14:10:39,495 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - [PID]154203
2023-03-19T14:10:39,496 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Torch worker started.
2023-03-19T14:10:39,496 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2023-03-19T14:10:39,524 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-03-19T14:10:39,561 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - model_name: trocr-handwritten, batchSize: 1
2023-03-19T14:10:40,245 [WARN ] W-9000-trocr-handwritten_1.0-stderr MODEL_LOG - Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
2023-03-19T14:10:47,374 [WARN ] W-9000-trocr-handwritten_1.0-stderr MODEL_LOG - Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']
2023-03-19T14:10:47,375 [WARN ] W-9000-trocr-handwritten_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2023-03-19T14:17:48,237 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Backend received inference at: 1679249868
2023-03-19T14:17:48,238 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-03-19T14:17:48,238 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-03-19T14:17:48,238 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/home/ziggy/miniconda3/envs/ts-testing/lib/python3.10/site-packages/ts/service.py", line 120, in predict
2023-03-19T14:17:48,238 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-03-19T14:17:48,238 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/tmp/models/94f835913c93475297dcea6e5bcbdc0b/handler.py", line 119, in handle
2023-03-19T14:17:48,238 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     model_input = self.preprocess(data)
2023-03-19T14:17:48,239 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/tmp/models/94f835913c93475297dcea6e5bcbdc0b/handler.py", line 85, in preprocess
2023-03-19T14:17:48,239 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     url_str = raw_data.decode("utf-8")
2023-03-19T14:17:48,239 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'decode'
2023-03-19T14:18:01,305 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Backend received inference at: 1679249881
2023-03-19T14:18:01,305 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-03-19T14:18:01,306 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-03-19T14:18:01,306 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/home/ziggy/miniconda3/envs/ts-testing/lib/python3.10/site-packages/ts/service.py", line 120, in predict
2023-03-19T14:18:01,306 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-03-19T14:18:01,306 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/tmp/models/94f835913c93475297dcea6e5bcbdc0b/handler.py", line 119, in handle
2023-03-19T14:18:01,306 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     model_input = self.preprocess(data)
2023-03-19T14:18:01,307 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/tmp/models/94f835913c93475297dcea6e5bcbdc0b/handler.py", line 85, in preprocess
2023-03-19T14:18:01,307 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     url_str = raw_data.decode("utf-8")
2023-03-19T14:18:01,307 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'decode'
2023-03-19T14:21:26,310 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Backend received inference at: 1679250086
2023-03-19T14:21:26,311 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Invoking custom service failed.
2023-03-19T14:21:26,311 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2023-03-19T14:21:26,311 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/home/ziggy/miniconda3/envs/ts-testing/lib/python3.10/site-packages/ts/service.py", line 120, in predict
2023-03-19T14:21:26,311 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2023-03-19T14:21:26,312 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/tmp/models/94f835913c93475297dcea6e5bcbdc0b/handler.py", line 119, in handle
2023-03-19T14:21:26,312 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     model_input = self.preprocess(data)
2023-03-19T14:21:26,312 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -   File "/tmp/models/94f835913c93475297dcea6e5bcbdc0b/handler.py", line 85, in preprocess
2023-03-19T14:21:26,312 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG -     url_str = raw_data.decode("utf-8")
2023-03-19T14:21:26,313 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'decode'
2023-03-19T14:21:49,240 [INFO ] W-9000-trocr-handwritten_1.0-stdout MODEL_LOG - Backend received inference at: 1679250109
2023-03-19T14:21:51,385 [WARN ] W-9000-trocr-handwritten_1.0-stderr MODEL_LOG - /home/ziggy/miniconda3/envs/ts-testing/lib/python3.10/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.
2023-03-19T14:21:51,385 [WARN ] W-9000-trocr-handwritten_1.0-stderr MODEL_LOG -   warnings.warn(
